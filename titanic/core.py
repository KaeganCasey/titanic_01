# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_core.ipynb (unless otherwise specified).

__all__ = ['LOG_MLFLOW', 'EXP_NAME', 'TARGET', 'STATE', 'n_estimators', 'max_depth', 'learning_rate', 'features',
           'raw_train', 'raw_test', 'df_list', 'drop_features', 'proc_df_list', 'proc_train', 'proc_test', 'proc_train',
           'clf', 'val_info', 'score_mean', 'score_std', 'clf', 'importance_df']

# Cell
import pandas as pd
pd.options.display.max_rows = 120
pd.options.display.max_columns = 120

import numpy as np

# plotting
import matplotlib.pyplot as plt
import seaborn as sns

# mlflow
import mlflow

# models
from xgboost import XGBClassifier

# helper libraries
from sklearn.model_selection import cross_validate, train_test_split

# custom packages
import sys
sys.path.append('../')
import titanic.preprocessing as prpr
import titanic.training as trn

# Cell
LOG_MLFLOW = False
EXP_NAME = 'Test_03-14'

TARGET = 'Survived'

STATE = 9

# Cell
n_estimators = 100
max_depth = 6
learning_rate = 0.3
#features = 'ALL'
features = ['Sex_female', 'Sex_male']

# Cell
if LOG_MLFLOW:
    EX_ID = mlflow.set_experiment(EXP_NAME)

# Cell
raw_train = pd.read_csv('../data/1_raw/train.csv')

# Cell
raw_test = pd.read_csv('../data/1_raw/test.csv')
raw_test.shape

# Cell
df_list = [raw_train, raw_test]
drop_features = ['PassengerId', 'Name', 'Ticket', 'Cabin']

proc_df_list = prpr.run(df_list, drop_features)
proc_train = proc_df_list[0]
proc_test = proc_df_list[1]

# Cell
prpr.save_interim_data(proc_train, 'interim_train')
prpr.save_interim_data(proc_test, 'interim_test')

# Cell
if isinstance(features, str):
    if features == 'ALL':
        features = proc_train.columns
    else:
        raise ValueError("features param is a string but does not take on the value 'ALL'.")
elif isinstance(features, list):
    features.insert(0, TARGET)
else:
    raise ValueError("features param is not a list or string.")

# Cell
proc_train = proc_train[features].copy()

# Cell
X_train, y_train = trn.seperate_xy(proc_train, TARGET)

# Cell
clf = XGBClassifier(n_estimators = n_estimators,
                    use_label_encoder = False,
                    max_depth = max_depth,
                    learning_rate = learning_rate,
                    random_state = STATE,
                    eval_metric = 'logloss')




val_info = cross_validate(
    clf,
    X_train,
    y_train,
    scoring='accuracy',
    return_estimator=True
)

score_mean = val_info['test_score'].mean()
score_std = val_info['test_score'].std()
print(f'{score_mean} accuracy with a standard deviation of {score_std}')

# Cell
clf = val_info['estimator'][0]

# Cell
importance_df = pd.DataFrame({'feature':X_train.columns, 'importance': clf.feature_importances_}).sort_values('importance', ascending=False)

# Cell
importance_df.to_html('../output/data/feature_importance.html', index=False)

# Cell
if LOG_MLFLOW:
    with mlflow.start_run(experiment_id=EX_ID):
        mlflow.log_param('num_features', X_train.shape[1])
        mlflow.log_param('n_estimators', clf.get_params()['n_estimators'])
        mlflow.log_param('max_depth', clf.get_params()['max_depth'])
        mlflow.log_param('learning_rate', clf.get_params()['learning_rate'])
        mlflow.log_param('booster', clf.get_params()['booster'])

        mlflow.log_metric('mean_accuracy', score_mean)
        mlflow.log_metric('std_accuracy', score_std)

        mlflow.log_artifact('../output/data/feature_importance.html')